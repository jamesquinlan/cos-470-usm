%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% SUMMARY    : Lecture 11 (Revised)
%            : Optimization & SVMs -- Deriving the Loss Function
%            : University of Southern Maine 
%            : @james.quinlan
%            : @abdirahman.mohamed, Wyatt McCurdy -> Modified by Mohamed Noor
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\section*{Objectives}
\begin{outline}
    \1 Understand monotonic functions and their properties.
    \1 Learn the formulation of SVMs through maximum margin optimization.
    \1 Study Lagrange multipliers in constrained optimization.
    \1 Explore gradients, partial derivatives, and various gradient descent methods.
    \1 Understand the primal problem (objective function) of SVMs.
    \1 Understand the dual problem using Lagrange multipliers.
    \1 Practice computing the gradient.
\end{outline}

\section{Mathematics and SVM Optimization}

\subsection{Monotonic Functions}
\begin{outline}
    \1 \textbf{Definition:} A function \( f(x) \) is \emph{monotonic} if whenever 
    \[
    x_1 \leq x_2, \quad \text{then} \quad f(x_1) \leq f(x_2).
    \]
    \1 \textbf{Takeaway:} A monotonic function preserves the order of inputs â€” as one input increases, the output either increases or stays the same (non-decreasing), or decreases or stays the same (non-increasing).
\end{outline}

\subsection{Maximum Margin in SVMs}
\begin{outline}
    \1 \textbf{Margin:} The gap between the decision boundary and the closest data points (support vectors).
    \1 \textbf{Goal:} Maximize the margin, which is equivalent to maximizing 
    \[
    \frac{1}{\|w\|}.
    \]
    \1 \textbf{Alternate Forms:} Minimizing any of these differentiable forms is equivalent:
    \begin{outline}
        \1 \(\|w\|\)
        \1 \(\|w\|^2\)
        \1 \(\frac{1}{2}\|w\|^2\)
    \end{outline}
\end{outline}

\subsection{SVM Optimization Setup (Primal Problem)}
\begin{outline}
    \1 \textbf{Objective:}
    \[
    \min \frac{1}{2}\|w\|^2.
    \]
    \1 \textbf{Constraints:} For every sample \((x_i, y_i)\),
    \[
    y_i (w^T x_i + b) \geq 1, \quad \text{or} \quad y_i (w^T x_i + b) - 1 \geq 0.
    \]
\end{outline}

\subsection{Lagrange Multipliers and the Dual Problem}
\begin{outline}
    \1 \textbf{Purpose:} Incorporate inequality constraints into the optimization problem using Lagrange multipliers.
    \1 \textbf{Why move to the dual?}

    Solving the primal problem directly can be challenging when the number of constraints is large. The dual problem transforms the constraints into a form that allows us to apply kernel methods and often simplifies computation. It also allows the use of inner products \( x_i^T x_j \), which is especially useful in high-dimensional feature spaces.

    \1 \textbf{Lagrangian Formulation:}
    \[
    L(w, b, \alpha) = \frac{1}{2}\|w\|^2 - \sumi \alpha_i \left( y_i (w^T x_i + b) - 1 \right).
    \]

    \1 \textbf{Compute Gradients and Set to Zero:}
    \begin{align}
        \frac{\partial L}{\partial w} &= w - \sumi \alpha_i y_i x_i = 0 \quad \Rightarrow \quad w = \sumi \alpha_i y_i x_i, \\
        \frac{\partial L}{\partial b} &= -\sumi \alpha_i y_i = 0 \quad \Rightarrow \quad \sumi \alpha_i y_i = 0.
    \end{align}

    \1 \textbf{Dual Problem:} Substituting \( w = \sumi \alpha_i y_i x_i \) back into \( L \), the dual objective becomes:
    \[
    \max_{\alpha} \quad \sumi \alpha_i - \frac{1}{2} \sumij \alpha_i \alpha_j y_i y_j x_i^T x_j,
    \]
    \[
    \text{subject to:} \quad \alpha_i \geq 0 \quad \text{and} \quad \sumi \alpha_i y_i = 0.
    \]
\end{outline}

\section{Computing the Gradient}

\subsection{Loss Function}
\[
L = \frac{1}{2}\|w\|^2 - \sumi \alpha_i \left( y_i (w^T x_i + b) - 1 \right).
\]

\subsection{Gradients}
\begin{align}
    \frac{\partial}{\partial w} \left( \frac{1}{2}\|w\|^2 \right) &= w, \\
    \frac{\partial}{\partial w} \sumi \alpha_i y_i w^T x_i &= \sumi \alpha_i y_i x_i, \\
    \frac{\partial}{\partial b} \sumi \alpha_i y_i b &= \sumi \alpha_i y_i.
\end{align}

Setting gradients to zero:
\[
w = \sumi \alpha_i y_i x_i, \quad \sumi \alpha_i y_i = 0.
\]

Substitute back into the loss:
\begin{align}
    L &= \sumi \alpha_i - \frac{1}{2} w^T w \\
      &= \sumi \alpha_i - \frac{1}{2} \left( \sumi \alpha_i y_i x_i \right)^T \left( \sum_{j=1}^n \alpha_j y_j x_j \right) \\
      &= \sumi \alpha_i - \frac{1}{2} \sumij \alpha_i \alpha_j y_i y_j x_i^T x_j.
\end{align}

\begin{tcolorbox}
\textbf{XPL1:} Demonstrate that 
\[
\sumi \sum_{j=1}^n \alpha_i \beta_j = \sumij \alpha_i \beta_j.
\]
\end{tcolorbox}

\section{Summary}
\begin{outline}
    \1 Reviewed monotonic functions and the concept of maximum margin in SVMs.
    \1 Set up the primal optimization problem for SVMs.
    \1 Incorporated constraints using Lagrange multipliers and derived the dual.
    \1 Computed gradients with respect to \( w \) and \( b \), then substituted them into the loss to obtain the dual objective.
\end{outline}

This dual formulation is fundamental to kernel-based methods and efficient optimization in Support Vector Machines.

 
 
